{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Solace-65/-GolfWebScraper/blob/main/ChinaCarOwners_Golf_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpbJ_EUnJ7xH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from googletrans import Translator\n",
        "from google.colab import files\n",
        "\n",
        "# Step 1: Load the CSV file from the specified path\n",
        "file_path = '/content/760k-Car-Owners-Nationwide-China-csv-2020.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Step 2: Use Google Translate API to translate column headers\n",
        "translator = Translator()\n",
        "\n",
        "# Translate column headers from Chinese to English\n",
        "original_headers = df.columns\n",
        "translated_headers = [translator.translate(header, src='zh-cn', dest='en').text for header in original_headers]\n",
        "\n",
        "# Apply the translated headers to the dataframe\n",
        "df.columns = translated_headers\n",
        "\n",
        "# Step 3: Function to clean the data\n",
        "def clean_data(df):\n",
        "    # Drop duplicates\n",
        "    df.drop_duplicates(inplace=True)\n",
        "\n",
        "    # Replace empty or NaN values with placeholder\n",
        "    df.replace('', np.nan, inplace=True)\n",
        "    df.dropna(how='all', inplace=True)  # Drop rows where all columns are NaN\n",
        "\n",
        "    # Further cleaning can be added based on specific data issues like format errors\n",
        "    return df\n",
        "\n",
        "# Step 4: Split the DataFrame into 4 chunks\n",
        "chunks = np.array_split(df, 4)\n",
        "\n",
        "# Initialize a garbage DataFrame to store discarded rows\n",
        "garbage_data = pd.DataFrame(columns=df.columns)\n",
        "\n",
        "# Step 5: Clean each chunk and append invalid rows to garbage data\n",
        "cleaned_chunks = []\n",
        "for chunk in chunks:\n",
        "    # Example: consider rows with NaN values as garbage (this logic can be customized)\n",
        "    invalid_rows = chunk[chunk.isna().any(axis=1)]\n",
        "    garbage_data = pd.concat([garbage_data, invalid_rows])\n",
        "\n",
        "    # Clean valid rows\n",
        "    valid_rows = clean_data(chunk.dropna())\n",
        "    cleaned_chunks.append(valid_rows)\n",
        "\n",
        "# Step 6: Save cleaned chunks and garbage data into separate CSV files\n",
        "for i, cleaned_chunk in enumerate(cleaned_chunks):\n",
        "    cleaned_chunk.to_csv(f'cleaned_chunk_{i+1}.csv', index=False)\n",
        "\n",
        "# Save garbage data\n",
        "garbage_data.to_csv('garbage_data.csv', index=False)\n",
        "\n",
        "# Download cleaned files and garbage file\n",
        "for i in range(1, 5):\n",
        "    files.download(f'cleaned_chunk_{i}.csv')\n",
        "\n",
        "files.download('garbage_data.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "chjO2Y4_ViAV",
        "outputId": "2a630c45-78d7-473d-887f-0709a69fa21d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-76c194b6ee13>:8: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n",
            "<ipython-input-2-76c194b6ee13>:43: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  garbage_data = pd.concat([garbage_data, invalid_rows])\n",
            "<ipython-input-2-76c194b6ee13>:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop_duplicates(inplace=True)\n",
            "<ipython-input-2-76c194b6ee13>:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.replace('', np.nan, inplace=True)\n",
            "<ipython-input-2-76c194b6ee13>:27: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.dropna(how='all', inplace=True)  # Drop rows where all columns are NaN\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0d02ff23-5bd0-49dd-8ad9-dbdf9542c3c3\", \"cleaned_chunk_1.csv\", 69079023)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_eead9c15-5841-4180-96da-4bd262e1bf26\", \"cleaned_chunk_2.csv\", 69065554)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_27492ae8-4f43-43f0-a914-096b9c825593\", \"cleaned_chunk_3.csv\", 69035430)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1637d67b-9933-40fc-9ead-c4ff84004eb1\", \"cleaned_chunk_4.csv\", 69040431)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_241e254b-4b2e-49b2-8844-cab1aecf5a2f\", \"garbage_data.csv\", 9246086)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from googletrans import Translator\n",
        "from google.colab import files\n",
        "\n",
        "# Step 1: Load the CSV file from the specified path\n",
        "file_path = '/content/760k-Car-Owners-Nationwide-China-csv-2020.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Step 2: Use Google Translate API to translate column headers\n",
        "translator = Translator()\n",
        "\n",
        "# Translate column headers from Chinese to English\n",
        "original_headers = df.columns\n",
        "translated_headers = [translator.translate(header, src='zh-cn', dest='en').text for header in original_headers]\n",
        "\n",
        "# Apply the translated headers to the dataframe\n",
        "df.columns = translated_headers\n",
        "\n",
        "# Step 3: Define a function to clean data\n",
        "def clean_data(df):\n",
        "    # Drop duplicates\n",
        "    df.drop_duplicates(inplace=True)\n",
        "\n",
        "    # Replace empty or NaN values with placeholder\n",
        "    df.replace('', np.nan, inplace=True)\n",
        "    df.dropna(how='all', inplace=True)  # Drop rows where all columns are NaN\n",
        "\n",
        "    # Further cleaning can be added based on specific data issues like format errors\n",
        "    return df\n",
        "\n",
        "# Step 4: Define a function to validate email addresses using regex\n",
        "def is_valid_email(email):\n",
        "    # Regex pattern for a valid email\n",
        "    email_regex = r'^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$'\n",
        "    if pd.isna(email):  # Handle NaN values\n",
        "        return False\n",
        "    return re.match(email_regex, email) is not None\n",
        "\n",
        "# Step 5: Split the DataFrame into 4 chunks\n",
        "chunks = np.array_split(df, 4)\n",
        "\n",
        "# Initialize a garbage DataFrame to store discarded rows\n",
        "garbage_data = pd.DataFrame(columns=df.columns)\n",
        "\n",
        "# Step 6: Clean each chunk, validate emails, and append invalid rows to garbage data\n",
        "cleaned_chunks = []\n",
        "for chunk in chunks:\n",
        "    # Example: consider rows with NaN values or invalid emails as garbage\n",
        "    if 'email' in chunk.columns:  # Assuming the email column is named 'email'\n",
        "        invalid_emails = chunk[~chunk['email'].apply(is_valid_email)]  # Filter invalid emails\n",
        "        garbage_data = pd.concat([garbage_data, invalid_emails])\n",
        "\n",
        "        # Clean valid rows (including only valid emails)\n",
        "        valid_rows = chunk[chunk['email'].apply(is_valid_email)]\n",
        "    else:\n",
        "        valid_rows = chunk\n",
        "\n",
        "    # Clean other data in the chunk\n",
        "    valid_rows_cleaned = clean_data(valid_rows)\n",
        "    cleaned_chunks.append(valid_rows_cleaned)\n",
        "\n",
        "# Step 7: Save cleaned chunks and garbage data into separate CSV files\n",
        "for i, cleaned_chunk in enumerate(cleaned_chunks):\n",
        "    cleaned_chunk.to_csv(f'cleaned_chunk_{i+1}.csv', index=False)\n",
        "\n",
        "# Save garbage data (invalid rows, including invalid emails)\n",
        "garbage_data.to_csv('garbage_data.csv', index=False)\n",
        "\n",
        "# Download cleaned files and garbage file\n",
        "for i in range(1, 5):\n",
        "    files.download(f'cleaned_chunk_{i}.csv')\n",
        "\n",
        "files.download('garbage_data.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "qppzcQnK4EIf",
        "outputId": "54df8eb7-a482-4ec9-b2c1-33e7c2d20a57"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b037ba44abdf>:9: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2c0c4cb0-c1cc-4767-a71a-065ee06deb74\", \"cleaned_chunk_1.csv\", 71378123)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_035b29f8-a2cb-447b-8873-2a7ebecc83f8\", \"cleaned_chunk_2.csv\", 71363271)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_37125d03-e175-45d4-9c72-355712c4e94f\", \"cleaned_chunk_3.csv\", 71365875)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_973e29a0-be25-4b4a-9715-e087a3fbf45c\", \"cleaned_chunk_4.csv\", 71359063)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7084546c-f3c0-4cd4-a539-e8e629342ba2\", \"garbage_data.csv\", 192)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from googletrans import Translator\n",
        "from google.colab import files\n",
        "\n",
        "# Step 1: Load the CSV file from the specified path\n",
        "file_path = '/content/760k-Car-Owners-Nationwide-China-csv-2020.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Step 2: Use Google Translate API to translate column headers\n",
        "translator = Translator()\n",
        "\n",
        "# Translate column headers from Chinese to English\n",
        "original_headers = df.columns\n",
        "translated_headers = [translator.translate(header, src='zh-cn', dest='en').text for header in original_headers]\n",
        "\n",
        "# Apply the translated headers to the dataframe\n",
        "df.columns = translated_headers\n",
        "\n",
        "# Step 3: Define a function to clean data\n",
        "def clean_data(df):\n",
        "    # Drop duplicates\n",
        "    df.drop_duplicates(inplace=True)\n",
        "\n",
        "    # Replace empty or NaN values with placeholder\n",
        "    df.replace('', np.nan, inplace=True)\n",
        "    df.dropna(how='all', inplace=True)  # Drop rows where all columns are NaN\n",
        "\n",
        "    # Further cleaning can be added based on specific data issues like format errors\n",
        "    return df\n",
        "\n",
        "# Step 4: Define a function to validate email addresses using regex\n",
        "def is_valid_email(email):\n",
        "    # Regex pattern for a valid email\n",
        "    email_regex = r'^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$'\n",
        "    if pd.isna(email):  # Handle NaN values\n",
        "        return False\n",
        "    return re.match(email_regex, email) is not None\n",
        "\n",
        "# Step 5: List of columns to remove and add to the garbage file\n",
        "columns_to_garbage = [\n",
        "    'gender', 'Province', 'City', 'address', 'post code', 'industry',\n",
        "    'Monthly salary', 'marriage', 'educate', 'Brand', 'Car',\n",
        "    'Model', 'configuation', 'color', 'unnamed:21'\n",
        "]\n",
        "\n",
        "# Step 6: Split the DataFrame into 4 chunks\n",
        "chunks = np.array_split(df, 4)\n",
        "\n",
        "# Initialize a garbage DataFrame to store discarded columns and rows\n",
        "garbage_data = pd.DataFrame(columns=df.columns)\n",
        "\n",
        "# Step 7: Clean each chunk, remove specified columns, validate emails, and append invalid rows/columns to garbage data\n",
        "cleaned_chunks = []\n",
        "for chunk in chunks:\n",
        "    # Drop duplicate rows within the chunk\n",
        "    chunk.drop_duplicates(inplace=True)\n",
        "\n",
        "    # Move specified columns to the garbage data\n",
        "    chunk_garbage = chunk[columns_to_garbage]\n",
        "    garbage_data = pd.concat([garbage_data, chunk_garbage], axis=0)\n",
        "\n",
        "    # Drop the garbage columns from the main chunk\n",
        "    chunk.drop(columns=columns_to_garbage, inplace=True)\n",
        "\n",
        "    # Example: consider rows with NaN values or invalid emails as garbage\n",
        "    if 'email' in chunk.columns:  # Assuming the email column is named 'email'\n",
        "        invalid_emails = chunk[~chunk['email'].apply(is_valid_email)]  # Filter invalid emails\n",
        "        garbage_data = pd.concat([garbage_data, invalid_emails], axis=0)\n",
        "\n",
        "        # Clean valid rows (including only valid emails)\n",
        "        valid_rows = chunk[chunk['email'].apply(is_valid_email)]\n",
        "    else:\n",
        "        valid_rows = chunk\n",
        "\n",
        "    # Clean other data in the chunk\n",
        "    valid_rows_cleaned = clean_data(valid_rows)\n",
        "    cleaned_chunks.append(valid_rows_cleaned)\n",
        "\n",
        "# Step 8: Save cleaned chunks and garbage data into separate CSV files\n",
        "for i, cleaned_chunk in enumerate(cleaned_chunks):\n",
        "    cleaned_chunk.to_csv(f'cleaned_chunk_{i+1}.csv', index=False)\n",
        "\n",
        "# Save garbage data (invalid rows and removed columns)\n",
        "garbage_data.to_csv('garbage_data.csv', index=False)\n",
        "\n",
        "# Download cleaned files and garbage file\n",
        "for i in range(1, 5):\n",
        "    files.download(f'cleaned_chunk_{i}.csv')\n",
        "\n",
        "files.download('garbage_data.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "l_DlzKbE_XsJ",
        "outputId": "8226c46b-692b-415e-f11b-c962264a16c4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-55754698c6a7>:9: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['configuation', 'unnamed:21'] not in index\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-55754698c6a7>\u001b[0m in \u001b[0;36m<cell line: 56>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# Move specified columns to the garbage data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mchunk_garbage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumns_to_garbage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mgarbage_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgarbage_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_garbage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6252\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6254\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['configuation', 'unnamed:21'] not in index\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from googletrans import Translator\n",
        "from google.colab import files\n",
        "\n",
        "# Step 1: Load the CSV file from the specified path, handle mixed types\n",
        "file_path = '/content/760k-Car-Owners-Nationwide-China-csv-2020.csv'\n",
        "df = pd.read_csv(file_path, low_memory=False)\n",
        "\n",
        "# Step 2: Use Google Translate API to translate column headers\n",
        "translator = Translator()\n",
        "\n",
        "# Translate column headers from Chinese to English\n",
        "original_headers = df.columns\n",
        "translated_headers = [translator.translate(header, src='zh-cn', dest='en').text for header in original_headers]\n",
        "\n",
        "# Apply the translated headers to the dataframe\n",
        "df.columns = translated_headers\n",
        "\n",
        "# Step 3: Define a function to clean data\n",
        "def clean_data(df):\n",
        "    # Drop duplicates\n",
        "    df.drop_duplicates(inplace=True)\n",
        "\n",
        "    # Replace empty or NaN values with placeholder\n",
        "    df.replace('', np.nan, inplace=True)\n",
        "    df.dropna(how='all', inplace=True)  # Drop rows where all columns are NaN\n",
        "\n",
        "    # Further cleaning can be added based on specific data issues like format errors\n",
        "    return df\n",
        "\n",
        "# Step 4: Define a function to validate email addresses using regex\n",
        "def is_valid_email(email):\n",
        "    # Regex pattern for a valid email\n",
        "    email_regex = r'^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$'\n",
        "    if pd.isna(email):  # Handle NaN values\n",
        "        return False\n",
        "    return re.match(email_regex, email) is not None\n",
        "\n",
        "# Step 5: List of columns to remove and add to the garbage file (corrected 'configuation' typo)\n",
        "columns_to_garbage = [\n",
        "    'gender', 'Province', 'City', 'address', 'post code', 'industry',\n",
        "    'Monthly salary', 'marriage', 'educate', 'Brand', 'Car',\n",
        "    'Model', 'configuration', 'color'\n",
        "]\n",
        "\n",
        "# Step 6: Split the DataFrame into 4 chunks\n",
        "chunks = np.array_split(df, 4)\n",
        "\n",
        "# Initialize a garbage DataFrame to store discarded columns and rows\n",
        "garbage_data = pd.DataFrame(columns=df.columns)\n",
        "\n",
        "# Step 7: Clean each chunk, remove specified columns, validate emails, and append invalid rows/columns to garbage data\n",
        "cleaned_chunks = []\n",
        "for chunk in chunks:\n",
        "    # Drop duplicate rows within the chunk\n",
        "    chunk.drop_duplicates(inplace=True)\n",
        "\n",
        "    # Move specified columns to the garbage data, but only those that exist\n",
        "    available_columns_to_garbage = [col for col in columns_to_garbage if col in chunk.columns]\n",
        "    chunk_garbage = chunk[available_columns_to_garbage]\n",
        "    garbage_data = pd.concat([garbage_data, chunk_garbage], axis=0)\n",
        "\n",
        "    # Drop the garbage columns from the main chunk\n",
        "    chunk.drop(columns=available_columns_to_garbage, inplace=True)\n",
        "\n",
        "    # Example: consider rows with NaN values or invalid emails as garbage\n",
        "    if 'email' in chunk.columns:  # Assuming the email column is named 'email'\n",
        "        invalid_emails = chunk[~chunk['email'].apply(is_valid_email)]  # Filter invalid emails\n",
        "        garbage_data = pd.concat([garbage_data, invalid_emails], axis=0)\n",
        "\n",
        "        # Clean valid rows (including only valid emails)\n",
        "        valid_rows = chunk[chunk['email'].apply(is_valid_email)]\n",
        "    else:\n",
        "        valid_rows = chunk\n",
        "\n",
        "    # Clean other data in the chunk\n",
        "    valid_rows_cleaned = clean_data(valid_rows)\n",
        "    cleaned_chunks.append(valid_rows_cleaned)\n",
        "\n",
        "# Step 8: Save cleaned chunks and garbage data into separate CSV files\n",
        "for i, cleaned_chunk in enumerate(cleaned_chunks):\n",
        "    cleaned_chunk.to_csv(f'cleaned_chunk_{i+1}.csv', index=False)\n",
        "\n",
        "# Save garbage data (invalid rows and removed columns)\n",
        "garbage_data.to_csv('garbage_data.csv', index=False)\n",
        "\n",
        "# Download cleaned files and garbage file\n",
        "for i in range(1, 5):\n",
        "    files.download(f'cleaned_chunk_{i}.csv')\n",
        "\n",
        "files.download('garbage_data.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "hg_fj9mODZG8",
        "outputId": "c3c00893-3a79-4e7e-80f0-d0d57737aa7c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n",
            "<ipython-input-6-1902cdb395cb>:63: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  garbage_data = pd.concat([garbage_data, chunk_garbage], axis=0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ac08c810-5e19-4455-8e67-84656d9d6f51\", \"cleaned_chunk_1.csv\", 26927037)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c78be515-9e0c-462c-9f41-b9f9f586431a\", \"cleaned_chunk_2.csv\", 26924186)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b6640474-0265-4637-ad2b-ec164d8fedf5\", \"cleaned_chunk_3.csv\", 26928100)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fc05694d-4530-4a84-a7b5-6a3c334c238f\", \"cleaned_chunk_4.csv\", 26931704)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_96037bab-95b3-4fbe-b221-41e156b0543c\", \"garbage_data.csv\", 184625563)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from googletrans import Translator\n",
        "from google.colab import files\n",
        "\n",
        "# Step 1: Load the CSV file from the specified path, handle mixed types\n",
        "file_path = '/content/760k-Car-Owners-Nationwide-China-csv-2020.csv'\n",
        "df = pd.read_csv(file_path, low_memory=False)\n",
        "\n",
        "# Step 2: Use Google Translate API to translate column headers\n",
        "translator = Translator()\n",
        "\n",
        "# Translate column headers from Chinese to English\n",
        "original_headers = df.columns\n",
        "translated_headers = [translator.translate(header, src='zh-cn', dest='en').text for header in original_headers]\n",
        "\n",
        "# Format headers: Replace spaces with underscores and convert to lowercase\n",
        "formatted_headers = [header.replace(' ', '_').lower() for header in translated_headers]\n",
        "\n",
        "# Apply the formatted headers to the dataframe\n",
        "df.columns = formatted_headers\n",
        "\n",
        "# Step 3: Define a function to clean data\n",
        "def clean_data(df):\n",
        "    # Drop duplicates\n",
        "    df.drop_duplicates(inplace=True)\n",
        "\n",
        "    # Replace empty or NaN values with placeholder\n",
        "    df.replace('', np.nan, inplace=True)\n",
        "    df.dropna(how='all', inplace=True)  # Drop rows where all columns are NaN\n",
        "\n",
        "    # Further cleaning can be added based on specific data issues like format errors\n",
        "    return df\n",
        "\n",
        "# Step 4: Define a function to validate email addresses using regex\n",
        "def is_valid_email(email):\n",
        "    # Regex pattern for a valid email\n",
        "    email_regex = r'^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$'\n",
        "    if pd.isna(email):  # Handle NaN values\n",
        "        return False\n",
        "    return re.match(email_regex, email) is not None\n",
        "\n",
        "# Step 5: List of columns to remove and add to the garbage file (with underscores and lowercased)\n",
        "columns_to_garbage = [\n",
        "    'gender', 'province', 'city', 'address', 'post_code', 'industry',\n",
        "    'monthly_salary', 'marriage', 'educate', 'brand', 'car',\n",
        "    'model', 'configuration', 'color'\n",
        "]\n",
        "\n",
        "# Step 6: Split the DataFrame into 4 chunks\n",
        "chunks = np.array_split(df, 4)\n",
        "\n",
        "# Initialize a garbage DataFrame to store discarded columns and rows\n",
        "garbage_data = pd.DataFrame(columns=df.columns)\n",
        "\n",
        "# Step 7: Clean each chunk, remove specified columns, validate emails, and append invalid rows/columns to garbage data\n",
        "cleaned_chunks = []\n",
        "for chunk in chunks:\n",
        "    # Drop duplicate rows within the chunk\n",
        "    chunk.drop_duplicates(inplace=True)\n",
        "\n",
        "    # Move specified columns to the garbage data, but only those that exist\n",
        "    available_columns_to_garbage = [col for col in columns_to_garbage if col in chunk.columns]\n",
        "    chunk_garbage = chunk[available_columns_to_garbage]\n",
        "    garbage_data = pd.concat([garbage_data, chunk_garbage], axis=0)\n",
        "\n",
        "    # Drop the garbage columns from the main chunk\n",
        "    chunk.drop(columns=available_columns_to_garbage, inplace=True)\n",
        "\n",
        "    # Example: consider rows with NaN values or invalid emails as garbage\n",
        "    if 'email' in chunk.columns:  # Assuming the email column is named 'email'\n",
        "        invalid_emails = chunk[~chunk['email'].apply(is_valid_email)]  # Filter invalid emails\n",
        "        garbage_data = pd.concat([garbage_data, invalid_emails], axis=0)\n",
        "\n",
        "        # Clean valid rows (including only valid emails)\n",
        "        valid_rows = chunk[chunk['email'].apply(is_valid_email)]\n",
        "    else:\n",
        "        valid_rows = chunk\n",
        "\n",
        "    # Clean other data in the chunk\n",
        "    valid_rows_cleaned = clean_data(valid_rows)\n",
        "    cleaned_chunks.append(valid_rows_cleaned)\n",
        "\n",
        "# Step 8: Save cleaned chunks and garbage data into separate CSV files\n",
        "for i, cleaned_chunk in enumerate(cleaned_chunks):\n",
        "    cleaned_chunk.to_csv(f'cleaned_chunk_{i+1}.csv', index=False)\n",
        "\n",
        "# Save garbage data (invalid rows and removed columns)\n",
        "garbage_data.to_csv('garbage_data.csv', index=False)\n",
        "\n",
        "# Download cleaned files and garbage file\n",
        "for i in range(1, 5):\n",
        "    files.download(f'cleaned_chunk_{i}.csv')\n",
        "\n",
        "files.download('garbage_data.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "Auv0Yk3GIeJK",
        "outputId": "6771d293-17c9-4bf3-b019-9d821da67068"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n",
            "<ipython-input-7-263207c8ca66>:66: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  garbage_data = pd.concat([garbage_data, chunk_garbage], axis=0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_34d5e0f0-9582-4261-ad61-5e278729e638\", \"cleaned_chunk_1.csv\", 19783913)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cdee6309-9a00-4b4d-8380-3a60dd934fac\", \"cleaned_chunk_2.csv\", 19783945)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ffe5da4c-e825-4d17-a932-c8f3e5bcec3f\", \"cleaned_chunk_3.csv\", 19784076)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7fbbeea3-a814-4210-8a9d-fe1603c8f945\", \"cleaned_chunk_4.csv\", 19784416)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b274228a-c022-4ac5-978f-14dd744a025d\", \"garbage_data.csv\", 212436798)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from googletrans import Translator\n",
        "from google.colab import files\n",
        "\n",
        "# Step 1: Load the CSV file from the specified path, handle mixed types\n",
        "file_path = '/content/760k-Car-Owners-Nationwide-China-csv-2020.csv'\n",
        "df = pd.read_csv(file_path, low_memory=False)\n",
        "\n",
        "# Step 2: Use Google Translate API to translate column headers\n",
        "translator = Translator()\n",
        "\n",
        "# Translate column headers from Chinese to English\n",
        "original_headers = df.columns\n",
        "translated_headers = [translator.translate(header, src='zh-cn', dest='en').text for header in original_headers]\n",
        "\n",
        "# Format headers: Replace spaces with underscores and convert to lowercase\n",
        "formatted_headers = [header.replace(' ', '_').lower() for header in translated_headers]\n",
        "\n",
        "# Apply the formatted headers to the dataframe\n",
        "df.columns = formatted_headers\n",
        "\n",
        "# Step 3: Define a function to clean data\n",
        "def clean_data(df):\n",
        "    # Drop duplicates\n",
        "    df.drop_duplicates(inplace=True)\n",
        "\n",
        "    # Replace empty or NaN values with placeholder\n",
        "    df.replace('', np.nan, inplace=True)\n",
        "    df.dropna(how='all', inplace=True)  # Drop rows where all columns are NaN\n",
        "\n",
        "    # Further cleaning can be added based on specific data issues like format errors\n",
        "    return df\n",
        "\n",
        "# Step 4: Define a function to validate email addresses using regex\n",
        "def is_valid_email(email):\n",
        "    # Regex pattern for a valid email\n",
        "    email_regex = r'^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$'\n",
        "    if pd.isna(email):  # Handle NaN values\n",
        "        return False\n",
        "    return re.match(email_regex, email) is not None\n",
        "\n",
        "# Step 5: List of columns to remove and add to the garbage file (with underscores and lowercased)\n",
        "columns_to_garbage = [\n",
        "    'gender', 'province', 'city', 'address', 'post_code', 'industry',\n",
        "    'monthly_salary', 'marriage', 'educate', 'brand', 'car',\n",
        "    'model', 'configuration', 'color'\n",
        "]\n",
        "\n",
        "# Step 6: Split the DataFrame into 4 chunks\n",
        "chunks = np.array_split(df, 4)\n",
        "\n",
        "# Initialize DataFrames to store all cleaned data and garbage data\n",
        "all_cleaned_data = pd.DataFrame()\n",
        "garbage_data = pd.DataFrame()\n",
        "\n",
        "# Step 7: Clean each chunk, remove specified columns, validate emails, and append invalid rows/columns to garbage data\n",
        "for chunk in chunks:\n",
        "    # Drop duplicate rows within the chunk\n",
        "    chunk.drop_duplicates(inplace=True)\n",
        "\n",
        "    # Move specified columns to the garbage data, but only those that exist\n",
        "    available_columns_to_garbage = [col for col in columns_to_garbage if col in chunk.columns]\n",
        "    chunk_garbage = chunk[available_columns_to_garbage]\n",
        "    garbage_data = pd.concat([garbage_data, chunk_garbage], axis=0)\n",
        "\n",
        "    # Drop the garbage columns from the main chunk\n",
        "    chunk.drop(columns=available_columns_to_garbage, inplace=True)\n",
        "\n",
        "    # Example: consider rows with NaN values or invalid emails as garbage\n",
        "    if 'email' in chunk.columns:  # Assuming the email column is named 'email'\n",
        "        invalid_emails = chunk[~chunk['email'].apply(is_valid_email)]  # Filter invalid emails\n",
        "        garbage_data = pd.concat([garbage_data, invalid_emails], axis=0)\n",
        "\n",
        "        # Clean valid rows (including only valid emails)\n",
        "        valid_rows = chunk[chunk['email'].apply(is_valid_email)]\n",
        "    else:\n",
        "        valid_rows = chunk\n",
        "\n",
        "    # Clean other data in the chunk\n",
        "    valid_rows_cleaned = clean_data(valid_rows)\n",
        "\n",
        "    # Append cleaned rows to the all_cleaned_data DataFrame\n",
        "    all_cleaned_data = pd.concat([all_cleaned_data, valid_rows_cleaned], axis=0)\n",
        "\n",
        "# Step 8: Save the merged cleaned data and garbage data into separate CSV files\n",
        "all_cleaned_data.to_csv('merged_cleaned_data.csv', index=False)\n",
        "garbage_data.to_csv('merged_garbage_data.csv', index=False)\n",
        "\n",
        "# Download the merged files\n",
        "files.download('merged_cleaned_data.csv')\n",
        "files.download('merged_garbage_data.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "l-fWj9BJL5I0",
        "outputId": "505780ef-3c07-42b6-ab44-2e5ae79f97d6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2a8414c2-576e-4145-b1ef-f001f797c147\", \"merged_cleaned_data.csv\", 79136122)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_bd15976e-4e6b-42ad-998f-9777fa13cfee\", \"merged_garbage_data.csv\", 206329634)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM3K+RMmmMpONJ1/uo0K1Na",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}